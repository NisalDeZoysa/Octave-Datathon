{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a84b7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e34d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "IMPROVED DRUG CLASSIFICATION MODEL\n",
      "============================================================\n",
      "\n",
      "[1/8] Loading data...\n",
      "✓ Train shape: (1500, 14)\n",
      "✓ Test shape: (377, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"IMPROVED DRUG CLASSIFICATION MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load data\n",
    "print(\"\\n[1/8] Loading data...\")\n",
    "train_df = pd.read_csv('data_minihackathon_train.csv')\n",
    "test_df = pd.read_csv('data_minihackathon_test.csv')\n",
    "print(f\"✓ Train shape: {train_df.shape}\")\n",
    "print(f\"✓ Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2648e308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/8] Handling missing values...\n",
      "✓ Train missing values: 31\n",
      "✓ Test missing values: 12\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "print(\"\\n[2/8] Handling missing values...\")\n",
    "train_missing = train_df.isnull().sum().sum()\n",
    "test_missing = test_df.isnull().sum().sum()\n",
    "print(f\"✓ Train missing values: {train_missing}\")\n",
    "print(f\"✓ Test missing values: {test_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fb199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with median\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].isnull().any():\n",
    "        median_val = train_df[col].median()\n",
    "        train_df[col].fillna(median_val, inplace=True)\n",
    "        test_df[col].fillna(median_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbba30f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/8] Engineering features...\n",
      "✓ Created 11 new features\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering\n",
    "print(\"\\n[3/8] Engineering features...\")\n",
    "def create_features(df):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Personality score interactions\n",
    "    df_new['N_E_interaction'] = df_new['Nscore'] * df_new['Escore']\n",
    "    df_new['O_A_interaction'] = df_new['Oscore'] * df_new['Ascore']\n",
    "    df_new['C_SS_interaction'] = df_new['Cscore'] * df_new['SS']\n",
    "    df_new['Impulsive_SS'] = df_new['Impulsive'] * df_new['SS']\n",
    "    \n",
    "    # Squared features for non-linear patterns\n",
    "    df_new['Nscore_sq'] = df_new['Nscore'] ** 2\n",
    "    df_new['SS_sq'] = df_new['SS'] ** 2\n",
    "    df_new['Impulsive_sq'] = df_new['Impulsive'] ** 2\n",
    "    \n",
    "    # Risk profile\n",
    "    df_new['risk_score'] = (df_new['Nscore'] + df_new['Impulsive'] + \n",
    "                             df_new['SS'] - df_new['Cscore'])\n",
    "    \n",
    "    # Personality sum and mean\n",
    "    personality_cols = ['Nscore', 'Escore', 'Oscore', 'Ascore', 'Cscore']\n",
    "    df_new['personality_sum'] = df_new[personality_cols].sum(axis=1)\n",
    "    df_new['personality_mean'] = df_new[personality_cols].mean(axis=1)\n",
    "    \n",
    "    # Age groups\n",
    "    df_new['Age_squared'] = df_new['Age'] ** 2\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)\n",
    "print(f\"✓ Created {train_df.shape[1] - 14} new features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8237e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/8] Preparing data...\n",
      "✓ Feature matrix shape: (1500, 23)\n",
      "✓ Target classes: ['Depressants' 'Hallucinogens' 'Stimulants']\n",
      "✓ Class distribution:\n",
      "  Depressants: 242 (16.1%)\n",
      "  Hallucinogens: 691 (46.1%)\n",
      "  Stimulants: 567 (37.8%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X = train_df.drop(['ID', 'drug_category'], axis=1)\n",
    "y = train_df['drug_category']\n",
    "X_test = test_df.drop(['ID'], axis=1)\n",
    "\n",
    "print(f\"\\n[4/8] Preparing data...\")\n",
    "print(f\"✓ Feature matrix shape: {X.shape}\")\n",
    "print(f\"✓ Target classes: {y.unique()}\")\n",
    "print(f\"✓ Class distribution:\")\n",
    "for cls in sorted(y.unique()):\n",
    "    count = (y == cls).sum()\n",
    "    pct = 100 * count / len(y)\n",
    "    print(f\"  {cls}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e059435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/8] Scaling features...\n",
      "✓ Features scaled\n"
     ]
    }
   ],
   "source": [
    "# Scale features\n",
    "print(\"\\n[5/8] Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"✓ Features scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7608fbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/8] Training ensemble models...\n"
     ]
    }
   ],
   "source": [
    "# Define models with optimized parameters\n",
    "print(\"\\n[6/8] Training ensemble models...\")\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='mlogloss'\n",
    "    ),\n",
    "    'LightGBM': LGBMClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=12,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'LogisticRegression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        C=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db3a332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Training XGBoost...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['Depressants' 'Hallucinogens' 'Stimulants']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m y_val_fold \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[0;32m     19\u001b[0m model_clone \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_params())\n\u001b[1;32m---> 20\u001b[0m \u001b[43mmodel_clone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m model_clone\u001b[38;5;241m.\u001b[39mpredict(X_val_fold)\n\u001b[0;32m     23\u001b[0m fold_score \u001b[38;5;241m=\u001b[39m accuracy_score(y_val_fold, val_pred)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Music\\DeepL\\myenvdeep\\Lib\\site-packages\\xgboost\\core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Music\\DeepL\\myenvdeep\\Lib\\site-packages\\xgboost\\sklearn.py:1758\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1753\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1755\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1756\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1757\u001b[0m ):\n\u001b[1;32m-> 1758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1759\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1761\u001b[0m     )\n\u001b[0;32m   1763\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['Depressants' 'Hallucinogens' 'Stimulants']"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = {}\n",
    "test_predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n  Training {name}...\")\n",
    "    fold_scores = []\n",
    "    fold_predictions = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y), 1):\n",
    "        X_train_fold = X_scaled[train_idx]\n",
    "        y_train_fold = y.iloc[train_idx]\n",
    "        X_val_fold = X_scaled[val_idx]\n",
    "        y_val_fold = y.iloc[val_idx]\n",
    "        \n",
    "        model_clone = model.__class__(**model.get_params())\n",
    "        model_clone.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        val_pred = model_clone.predict(X_val_fold)\n",
    "        fold_score = accuracy_score(y_val_fold, val_pred)\n",
    "        fold_scores.append(fold_score)\n",
    "        \n",
    "        # Predict on test set\n",
    "        test_pred = model_clone.predict(X_test_scaled)\n",
    "        fold_predictions.append(test_pred)\n",
    "    \n",
    "    cv_scores[name] = fold_scores\n",
    "    # Average predictions across folds (majority voting)\n",
    "    test_predictions[name] = np.array(fold_predictions)\n",
    "    \n",
    "    mean_score = np.mean(fold_scores)\n",
    "    std_score = np.std(fold_scores)\n",
    "    print(f\"    CV Accuracy: {mean_score:.4f} (+/- {std_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e808e18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "IMPROVED DRUG CLASSIFICATION MODEL\n",
      "============================================================\n",
      "\n",
      "[1/8] Loading data...\n",
      "✓ Train shape: (1500, 14)\n",
      "✓ Test shape: (377, 13)\n",
      "\n",
      "[2/8] Handling missing values...\n",
      "✓ Train missing values: 31\n",
      "✓ Test missing values: 12\n",
      "\n",
      "[3/8] Engineering features...\n",
      "✓ Created 11 new features\n",
      "\n",
      "[4/8] Preparing data...\n",
      "✓ Feature matrix shape: (1500, 23)\n",
      "✓ Target classes: ['Depressants' 'Hallucinogens' 'Stimulants']\n",
      "✓ Class mapping: {'Depressants': 0, 'Hallucinogens': 1, 'Stimulants': 2}\n",
      "✓ Class distribution:\n",
      "  Depressants: 242 (16.1%)\n",
      "  Hallucinogens: 691 (46.1%)\n",
      "  Stimulants: 567 (37.8%)\n",
      "\n",
      "[5/8] Scaling features...\n",
      "✓ Features scaled\n",
      "\n",
      "[6/8] Training ensemble models...\n",
      "\n",
      "  Training XGBoost...\n",
      "    CV Accuracy: 0.7020 (+/- 0.0206)\n",
      "\n",
      "  Training LightGBM...\n",
      "    CV Accuracy: 0.6920 (+/- 0.0183)\n",
      "\n",
      "  Training RandomForest...\n",
      "    CV Accuracy: 0.7113 (+/- 0.0201)\n",
      "\n",
      "  Training GradientBoosting...\n",
      "    CV Accuracy: 0.7127 (+/- 0.0168)\n",
      "\n",
      "  Training LogisticRegression...\n",
      "    CV Accuracy: 0.7093 (+/- 0.0144)\n",
      "\n",
      "[7/8] Creating weighted ensemble...\n",
      "\n",
      "Model Performance Summary:\n",
      "------------------------------------------------------------\n",
      "XGBoost             : 0.7020 (+/- 0.0206)\n",
      "LightGBM            : 0.6920 (+/- 0.0183)\n",
      "RandomForest        : 0.7113 (+/- 0.0201)\n",
      "GradientBoosting    : 0.7127 (+/- 0.0168)\n",
      "LogisticRegression  : 0.7093 (+/- 0.0144)\n",
      "Ensemble (estimated): 0.7055\n",
      "\n",
      "[8/8] Creating submission file...\n",
      "✓ Submission saved to 'improved_submission.csv'\n",
      "\n",
      "============================================================\n",
      "PREDICTION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Predicted class distribution:\n",
      "  Depressants: 11 (2.9%)\n",
      "  Hallucinogens: 200 (53.1%)\n",
      "  Stimulants: 166 (44.0%)\n",
      "\n",
      "✓ COMPLETE - Check 'improved_submission.csv' for results\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"IMPROVED DRUG CLASSIFICATION MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load data\n",
    "print(\"\\n[1/8] Loading data...\")\n",
    "train_df = pd.read_csv('data_minihackathon_train.csv')\n",
    "test_df = pd.read_csv('data_minihackathon_test.csv')\n",
    "print(f\"✓ Train shape: {train_df.shape}\")\n",
    "print(f\"✓ Test shape: {test_df.shape}\")\n",
    "\n",
    "# Handle missing values\n",
    "print(\"\\n[2/8] Handling missing values...\")\n",
    "train_missing = train_df.isnull().sum().sum()\n",
    "test_missing = test_df.isnull().sum().sum()\n",
    "print(f\"✓ Train missing values: {train_missing}\")\n",
    "print(f\"✓ Test missing values: {test_missing}\")\n",
    "\n",
    "# Fill missing values with median\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].isnull().any():\n",
    "        median_val = train_df[col].median()\n",
    "        train_df[col].fillna(median_val, inplace=True)\n",
    "        test_df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "print(\"\\n[3/8] Engineering features...\")\n",
    "def create_features(df):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Personality score interactions\n",
    "    df_new['N_E_interaction'] = df_new['Nscore'] * df_new['Escore']\n",
    "    df_new['O_A_interaction'] = df_new['Oscore'] * df_new['Ascore']\n",
    "    df_new['C_SS_interaction'] = df_new['Cscore'] * df_new['SS']\n",
    "    df_new['Impulsive_SS'] = df_new['Impulsive'] * df_new['SS']\n",
    "    \n",
    "    # Squared features for non-linear patterns\n",
    "    df_new['Nscore_sq'] = df_new['Nscore'] ** 2\n",
    "    df_new['SS_sq'] = df_new['SS'] ** 2\n",
    "    df_new['Impulsive_sq'] = df_new['Impulsive'] ** 2\n",
    "    \n",
    "    # Risk profile\n",
    "    df_new['risk_score'] = (df_new['Nscore'] + df_new['Impulsive'] + \n",
    "                             df_new['SS'] - df_new['Cscore'])\n",
    "    \n",
    "    # Personality sum and mean\n",
    "    personality_cols = ['Nscore', 'Escore', 'Oscore', 'Ascore', 'Cscore']\n",
    "    df_new['personality_sum'] = df_new[personality_cols].sum(axis=1)\n",
    "    df_new['personality_mean'] = df_new[personality_cols].mean(axis=1)\n",
    "    \n",
    "    # Age groups\n",
    "    df_new['Age_squared'] = df_new['Age'] ** 2\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)\n",
    "print(f\"✓ Created {train_df.shape[1] - 14} new features\")\n",
    "\n",
    "# Prepare features and target\n",
    "X = train_df.drop(['ID', 'drug_category'], axis=1)\n",
    "y = train_df['drug_category']\n",
    "X_test = test_df.drop(['ID'], axis=1)\n",
    "\n",
    "print(f\"\\n[4/8] Preparing data...\")\n",
    "print(f\"✓ Feature matrix shape: {X.shape}\")\n",
    "print(f\"✓ Target classes: {y.unique()}\")\n",
    "\n",
    "# Encode target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "class_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(f\"✓ Class mapping: {class_mapping}\")\n",
    "\n",
    "print(f\"✓ Class distribution:\")\n",
    "for cls in sorted(y.unique()):\n",
    "    count = (y == cls).sum()\n",
    "    pct = 100 * count / len(y)\n",
    "    print(f\"  {cls}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Update y to use encoded values\n",
    "y = pd.Series(y_encoded, index=y.index)\n",
    "\n",
    "# Scale features\n",
    "print(\"\\n[5/8] Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"✓ Features scaled\")\n",
    "\n",
    "# Define models with optimized parameters\n",
    "print(\"\\n[6/8] Training ensemble models...\")\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='mlogloss'\n",
    "    ),\n",
    "    'LightGBM': LGBMClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=12,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'LogisticRegression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        C=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# Cross-validation\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = {}\n",
    "test_predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n  Training {name}...\")\n",
    "    fold_scores = []\n",
    "    fold_predictions = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y), 1):\n",
    "        X_train_fold = X_scaled[train_idx]\n",
    "        y_train_fold = y.iloc[train_idx]\n",
    "        X_val_fold = X_scaled[val_idx]\n",
    "        y_val_fold = y.iloc[val_idx]\n",
    "        \n",
    "        model_clone = model.__class__(**model.get_params())\n",
    "        model_clone.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        val_pred = model_clone.predict(X_val_fold)\n",
    "        fold_score = accuracy_score(y_val_fold, val_pred)\n",
    "        fold_scores.append(fold_score)\n",
    "        \n",
    "        # Predict on test set\n",
    "        test_pred = model_clone.predict(X_test_scaled)\n",
    "        fold_predictions.append(test_pred)\n",
    "    \n",
    "    cv_scores[name] = fold_scores\n",
    "    # Average predictions across folds (majority voting)\n",
    "    test_predictions[name] = np.array(fold_predictions)\n",
    "    \n",
    "    mean_score = np.mean(fold_scores)\n",
    "    std_score = np.std(fold_scores)\n",
    "    print(f\"    CV Accuracy: {mean_score:.4f} (+/- {std_score:.4f})\")\n",
    "\n",
    "# Weighted ensemble\n",
    "print(\"\\n[7/8] Creating weighted ensemble...\")\n",
    "weights = {\n",
    "    'XGBoost': 0.30,\n",
    "    'LightGBM': 0.30,\n",
    "    'RandomForest': 0.20,\n",
    "    'GradientBoosting': 0.15,\n",
    "    'LogisticRegression': 0.05\n",
    "}\n",
    "\n",
    "# Majority voting with weights\n",
    "ensemble_predictions = []\n",
    "for i in range(len(X_test)):\n",
    "    votes = {}\n",
    "    for model_name, preds in test_predictions.items():\n",
    "        # Average predictions across folds for this model\n",
    "        model_pred = pd.Series([fold_preds[i] for fold_preds in preds]).mode()[0]\n",
    "        weight = weights[model_name]\n",
    "        votes[model_pred] = votes.get(model_pred, 0) + weight\n",
    "    \n",
    "    # Select class with highest weighted vote\n",
    "    final_pred = max(votes, key=votes.get)\n",
    "    ensemble_predictions.append(final_pred)\n",
    "\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(\"-\" * 60)\n",
    "for name, scores in cv_scores.items():\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    print(f\"{name:20s}: {mean_score:.4f} (+/- {std_score:.4f})\")\n",
    "\n",
    "ensemble_cv = np.mean([np.mean(scores) for scores in cv_scores.values()])\n",
    "print(f\"{'Ensemble (estimated)':20s}: {ensemble_cv:.4f}\")\n",
    "\n",
    "# Create submission\n",
    "print(\"\\n[8/8] Creating submission file...\")\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "ensemble_predictions_decoded = le.inverse_transform(ensemble_predictions)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'drug_category': ensemble_predictions_decoded\n",
    "})\n",
    "\n",
    "submission.to_csv('improved_submission.csv', index=False)\n",
    "print(\"✓ Submission saved to 'improved_submission.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREDICTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "pred_counts = submission['drug_category'].value_counts().sort_index()\n",
    "print(\"\\nPredicted class distribution:\")\n",
    "for cls in pred_counts.index:\n",
    "    count = pred_counts[cls]\n",
    "    pct = 100 * count / len(submission)\n",
    "    print(f\"  {cls}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n✓ COMPLETE - Check 'improved_submission.csv' for results\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f0230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvdeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
